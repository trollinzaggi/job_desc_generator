{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Clustering Analysis\n",
    "\n",
    "This notebook analyzes the HDBSCAN clustering results.\n",
    "\n",
    "**What to look for:**\n",
    "- Experiment comparison (if multiple)\n",
    "- Cluster size distribution\n",
    "- Noise ratio and outliers\n",
    "- Division purity (do clusters align with divisions?)\n",
    "- Visual cluster separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "from config import get_output_path\n",
    "from src.archetypes.extraction import RequirementExtractor\n",
    "from src.archetypes.feature_engineering import FeatureOutput\n",
    "from src.archetypes.clustering import ClusteringResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load extraction results (for metadata and skills)\n",
    "extraction_path = get_output_path(\"archetypes\", \"phase_1_extraction\", \"extracted_requirements.json\")\n",
    "extractions = RequirementExtractor.load_results(str(extraction_path))\n",
    "extraction_lookup = {e.jd_id: e for e in extractions}\n",
    "print(f\"‚úÖ Loaded {len(extractions)} extractions\")\n",
    "\n",
    "# Build metadata DataFrame\n",
    "metadata_records = []\n",
    "for e in extractions:\n",
    "    if e.extraction_success:\n",
    "        record = {'jd_id': e.jd_id}\n",
    "        record.update(e.metadata)\n",
    "        record['top_skills'] = ', '.join(e.get_all_skills_flat()[:5])\n",
    "        metadata_records.append(record)\n",
    "\n",
    "metadata_df = pd.DataFrame(metadata_records)\n",
    "print(f\"‚úÖ Built metadata for {len(metadata_df)} JDs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load clustering results\n",
    "cluster_dir = get_output_path(\"archetypes\", \"phase_3_clustering\")\n",
    "\n",
    "clustering_results = {}\n",
    "if cluster_dir.exists():\n",
    "    # Check for experiment results\n",
    "    exp_results_file = cluster_dir / \"experiment_results.json\"\n",
    "    if exp_results_file.exists():\n",
    "        with open(exp_results_file) as f:\n",
    "            experiment_data = json.load(f)\n",
    "        print(f\"‚úÖ Loaded {len(experiment_data)} experiment results\")\n",
    "    else:\n",
    "        experiment_data = None\n",
    "    \n",
    "    # Load individual clustering results\n",
    "    for subdir in cluster_dir.iterdir():\n",
    "        if subdir.is_dir() and (subdir / \"cluster_labels.npy\").exists():\n",
    "            clustering_results[subdir.name] = ClusteringResult.load(str(subdir))\n",
    "            print(f\"‚úÖ Loaded clustering: {subdir.name} - {clustering_results[subdir.name].n_clusters} clusters\")\n",
    "\n",
    "if not clustering_results:\n",
    "    print(\"‚ùå No clustering results found. Run: python run_archetype_pipeline.py --cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature outputs (for UMAP visualization)\n",
    "feature_dir = get_output_path(\"archetypes\", \"phase_2_features\")\n",
    "feature_outputs = {}\n",
    "\n",
    "if feature_dir.exists():\n",
    "    for subdir in feature_dir.iterdir():\n",
    "        if subdir.is_dir() and (subdir / \"features.npy\").exists():\n",
    "            feature_outputs[subdir.name] = FeatureOutput.load(str(subdir))\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(feature_outputs)} feature outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Experiment Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load experiment comparison if available\n",
    "comparison_file = cluster_dir / \"experiment_comparison.csv\"\n",
    "\n",
    "if comparison_file.exists():\n",
    "    comparison_df = pd.read_csv(comparison_file)\n",
    "    display(comparison_df.style.background_gradient(subset=['silhouette_score'], cmap='Greens')\n",
    "                               .background_gradient(subset=['noise_ratio'], cmap='Reds_r'))\n",
    "else:\n",
    "    # Build comparison from loaded results\n",
    "    comparison_data = []\n",
    "    for name, cr in clustering_results.items():\n",
    "        comparison_data.append({\n",
    "            'experiment': name,\n",
    "            'n_clusters': cr.n_clusters,\n",
    "            'n_noise': cr.n_noise,\n",
    "            'noise_ratio': cr.noise_ratio,\n",
    "            'silhouette_score': cr.silhouette_score,\n",
    "        })\n",
    "    \n",
    "    if comparison_data:\n",
    "        comparison_df = pd.DataFrame(comparison_data)\n",
    "        display(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhouette vs Noise tradeoff\n",
    "if len(comparison_df) > 1:\n",
    "    fig = px.scatter(\n",
    "        comparison_df,\n",
    "        x='noise_ratio',\n",
    "        y='silhouette_score',\n",
    "        size='n_clusters',\n",
    "        color='experiment' if 'experiment' in comparison_df.columns else 'experiment_id',\n",
    "        hover_data=comparison_df.columns.tolist(),\n",
    "        title='Silhouette Score vs Noise Ratio (size = # clusters)'\n",
    "    )\n",
    "    fig.update_layout(height=500, width=700)\n",
    "    fig.show()\n",
    "    \n",
    "    print(\"\\nüí° Ideal: High silhouette (top) + Low noise (left)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cluster Size Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select clustering result to analyze\n",
    "if clustering_results:\n",
    "    # Use 'default' if available, else first one\n",
    "    default_name = 'default' if 'default' in clustering_results else list(clustering_results.keys())[0]\n",
    "    \n",
    "    cluster_dropdown = widgets.Dropdown(\n",
    "        options=list(clustering_results.keys()),\n",
    "        value=default_name,\n",
    "        description='Clustering:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    output = widgets.Output()\n",
    "    \n",
    "    def show_cluster_sizes(change):\n",
    "        with output:\n",
    "            output.clear_output(wait=True)\n",
    "            \n",
    "            cr = clustering_results[change['new']]\n",
    "            \n",
    "            # Cluster sizes (excluding noise)\n",
    "            sizes = {k: v for k, v in cr.cluster_sizes.items() if k != -1}\n",
    "            noise_size = cr.cluster_sizes.get(-1, 0)\n",
    "            \n",
    "            sizes_df = pd.DataFrame([\n",
    "                {'Cluster': f'Cluster {k}', 'Size': v}\n",
    "                for k, v in sorted(sizes.items())\n",
    "            ])\n",
    "            \n",
    "            # Add noise as separate bar\n",
    "            if noise_size > 0:\n",
    "                sizes_df = pd.concat([\n",
    "                    sizes_df,\n",
    "                    pd.DataFrame([{'Cluster': 'Noise (-1)', 'Size': noise_size}])\n",
    "                ])\n",
    "            \n",
    "            fig = px.bar(\n",
    "                sizes_df, x='Cluster', y='Size',\n",
    "                title=f'Cluster Sizes ({len(sizes)} clusters + noise)',\n",
    "                color='Size',\n",
    "                color_continuous_scale='Blues'\n",
    "            )\n",
    "            fig.update_layout(height=400, width=800)\n",
    "            fig.show()\n",
    "            \n",
    "            # Summary stats\n",
    "            size_values = list(sizes.values())\n",
    "            print(f\"\\nüìä Cluster Size Statistics (excluding noise):\")\n",
    "            print(f\"   Min: {min(size_values)}\")\n",
    "            print(f\"   Max: {max(size_values)}\")\n",
    "            print(f\"   Mean: {np.mean(size_values):.1f}\")\n",
    "            print(f\"   Median: {np.median(size_values):.1f}\")\n",
    "            print(f\"   Std: {np.std(size_values):.1f}\")\n",
    "    \n",
    "    cluster_dropdown.observe(show_cluster_sizes, names='value')\n",
    "    display(cluster_dropdown)\n",
    "    display(output)\n",
    "    show_cluster_sizes({'new': default_name})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. UMAP with Cluster Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute UMAP and color by cluster\n",
    "try:\n",
    "    import umap\n",
    "    UMAP_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è umap-learn not installed\")\n",
    "    UMAP_AVAILABLE = False\n",
    "\n",
    "if UMAP_AVAILABLE and clustering_results and feature_outputs:\n",
    "    # Dropdown for selecting clustering result\n",
    "    cluster_dropdown = widgets.Dropdown(\n",
    "        options=list(clustering_results.keys()),\n",
    "        value=list(clustering_results.keys())[0],\n",
    "        description='Clustering:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Dropdown for feature set (for UMAP)\n",
    "    feature_dropdown = widgets.Dropdown(\n",
    "        options=list(feature_outputs.keys()),\n",
    "        value=list(feature_outputs.keys())[0],\n",
    "        description='Features:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    output = widgets.Output()\n",
    "    \n",
    "    # Cache UMAP results\n",
    "    umap_cache = {}\n",
    "    \n",
    "    def show_cluster_umap(change):\n",
    "        with output:\n",
    "            output.clear_output(wait=True)\n",
    "            \n",
    "            cluster_name = cluster_dropdown.value\n",
    "            feature_name = feature_dropdown.value\n",
    "            \n",
    "            cr = clustering_results[cluster_name]\n",
    "            fo = feature_outputs[feature_name]\n",
    "            \n",
    "            # Compute UMAP (cached)\n",
    "            if feature_name not in umap_cache:\n",
    "                print(f\"Computing UMAP for {feature_name}...\")\n",
    "                reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "                umap_cache[feature_name] = reducer.fit_transform(fo.features)\n",
    "            \n",
    "            embedding_2d = umap_cache[feature_name]\n",
    "            \n",
    "            # Build DataFrame\n",
    "            id_to_cluster = dict(zip(cr.ids, cr.labels))\n",
    "            \n",
    "            plot_df = pd.DataFrame({\n",
    "                'jd_id': fo.ids,\n",
    "                'x': embedding_2d[:, 0],\n",
    "                'y': embedding_2d[:, 1],\n",
    "            })\n",
    "            plot_df['cluster'] = plot_df['jd_id'].map(id_to_cluster)\n",
    "            plot_df = plot_df.merge(metadata_df, on='jd_id', how='left')\n",
    "            \n",
    "            # Convert cluster to string for discrete colors\n",
    "            plot_df['cluster_label'] = plot_df['cluster'].apply(\n",
    "                lambda x: 'Noise' if x == -1 else f'Cluster {x}'\n",
    "            )\n",
    "            \n",
    "            # Hover data\n",
    "            hover_cols = ['jd_id', 'cluster']\n",
    "            if 'title' in plot_df.columns:\n",
    "                hover_cols.append('title')\n",
    "            if 'top_skills' in plot_df.columns:\n",
    "                hover_cols.append('top_skills')\n",
    "            if 'division' in plot_df.columns:\n",
    "                hover_cols.append('division')\n",
    "            \n",
    "            fig = px.scatter(\n",
    "                plot_df, x='x', y='y',\n",
    "                color='cluster_label',\n",
    "                hover_data=hover_cols,\n",
    "                title=f'UMAP: {feature_name} (colored by {cluster_name})'\n",
    "            )\n",
    "            \n",
    "            fig.update_layout(height=600, width=900)\n",
    "            fig.update_traces(marker=dict(size=6, opacity=0.7))\n",
    "            fig.show()\n",
    "    \n",
    "    cluster_dropdown.observe(show_cluster_umap, names='value')\n",
    "    feature_dropdown.observe(show_cluster_umap, names='value')\n",
    "    \n",
    "    display(widgets.HBox([cluster_dropdown, feature_dropdown]))\n",
    "    display(output)\n",
    "    show_cluster_umap(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Division Purity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute division purity for each cluster\n",
    "if 'division' in metadata_df.columns and clustering_results:\n",
    "    cr = clustering_results[list(clustering_results.keys())[0]]\n",
    "    \n",
    "    # Build cluster -> division mapping\n",
    "    id_to_cluster = dict(zip(cr.ids, cr.labels))\n",
    "    analysis_df = metadata_df.copy()\n",
    "    analysis_df['cluster'] = analysis_df['jd_id'].map(id_to_cluster)\n",
    "    analysis_df = analysis_df.dropna(subset=['cluster'])\n",
    "    analysis_df['cluster'] = analysis_df['cluster'].astype(int)\n",
    "    \n",
    "    # Exclude noise\n",
    "    analysis_df = analysis_df[analysis_df['cluster'] != -1]\n",
    "    \n",
    "    # Compute purity\n",
    "    purity_data = []\n",
    "    for cluster_id in sorted(analysis_df['cluster'].unique()):\n",
    "        cluster_data = analysis_df[analysis_df['cluster'] == cluster_id]\n",
    "        division_counts = cluster_data['division'].value_counts()\n",
    "        \n",
    "        dominant_division = division_counts.index[0]\n",
    "        dominant_count = division_counts.iloc[0]\n",
    "        total = len(cluster_data)\n",
    "        purity = dominant_count / total\n",
    "        \n",
    "        purity_data.append({\n",
    "            'cluster': cluster_id,\n",
    "            'size': total,\n",
    "            'dominant_division': dominant_division,\n",
    "            'purity': purity,\n",
    "            'n_divisions': len(division_counts),\n",
    "        })\n",
    "    \n",
    "    purity_df = pd.DataFrame(purity_data)\n",
    "    \n",
    "    # Overall purity\n",
    "    overall_purity = sum(p['purity'] * p['size'] for p in purity_data) / sum(p['size'] for p in purity_data)\n",
    "    \n",
    "    print(f\"\\nüìä Division Purity Analysis\")\n",
    "    print(f\"   Overall Purity: {overall_purity:.1%}\")\n",
    "    print(f\"   Mean Cluster Purity: {purity_df['purity'].mean():.1%}\")\n",
    "    \n",
    "    display(purity_df.sort_values('purity', ascending=False).style\n",
    "            .background_gradient(subset=['purity'], cmap='Greens'))\n",
    "    \n",
    "    # Purity histogram\n",
    "    fig = px.histogram(purity_df, x='purity', nbins=20,\n",
    "                       title='Distribution of Cluster Purity Scores')\n",
    "    fig.add_vline(x=overall_purity, line_dash='dash', line_color='red',\n",
    "                  annotation_text=f'Overall: {overall_purity:.1%}')\n",
    "    fig.update_layout(height=400, width=600)\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Division field not available for purity analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cluster x Division Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of cluster vs division\n",
    "if 'division' in metadata_df.columns and clustering_results:\n",
    "    # Create cross-tabulation\n",
    "    crosstab = pd.crosstab(analysis_df['cluster'], analysis_df['division'], normalize='index')\n",
    "    \n",
    "    fig = px.imshow(\n",
    "        crosstab,\n",
    "        labels=dict(x='Division', y='Cluster', color='Proportion'),\n",
    "        title='Cluster vs Division (row-normalized)',\n",
    "        color_continuous_scale='Blues'\n",
    "    )\n",
    "    fig.update_layout(height=500, width=700)\n",
    "    fig.show()\n",
    "    \n",
    "    print(\"\\nüí° Interpretation:\")\n",
    "    print(\"   - Bright rows = cluster dominated by one division (high purity)\")\n",
    "    print(\"   - Even rows = cluster spans multiple divisions (low purity)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Noise Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze noise points\n",
    "if clustering_results:\n",
    "    cr = clustering_results[list(clustering_results.keys())[0]]\n",
    "    \n",
    "    noise_ids = cr.get_noise_ids()\n",
    "    \n",
    "    if noise_ids:\n",
    "        print(f\"\\nüîç Noise Analysis: {len(noise_ids)} JDs marked as noise ({cr.noise_ratio:.1%})\")\n",
    "        \n",
    "        # Get metadata for noise points\n",
    "        noise_df = metadata_df[metadata_df['jd_id'].isin(noise_ids)]\n",
    "        \n",
    "        # Show division distribution of noise\n",
    "        if 'division' in noise_df.columns:\n",
    "            print(\"\\nüìä Division distribution in noise:\")\n",
    "            display(noise_df['division'].value_counts())\n",
    "        \n",
    "        # Show sample noise JDs\n",
    "        print(\"\\nüìã Sample noise JDs:\")\n",
    "        for jd_id in noise_ids[:5]:\n",
    "            ext = extraction_lookup.get(jd_id)\n",
    "            if ext:\n",
    "                title = ext.metadata.get('title', 'Unknown')\n",
    "                skills = ext.get_all_skills_flat()[:5]\n",
    "                print(f\"   - {jd_id}: {title}\")\n",
    "                print(f\"     Skills: {', '.join(skills)}\")\n",
    "    else:\n",
    "        print(\"‚úÖ No noise points - all JDs assigned to clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cluster Drill-Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive cluster explorer\n",
    "if clustering_results:\n",
    "    cr = clustering_results[list(clustering_results.keys())[0]]\n",
    "    \n",
    "    cluster_ids = sorted([k for k in cr.cluster_sizes.keys() if k != -1])\n",
    "    cluster_options = [(f\"Cluster {c} ({cr.cluster_sizes[c]} JDs)\", c) for c in cluster_ids]\n",
    "    \n",
    "    cluster_select = widgets.Dropdown(\n",
    "        options=cluster_options,\n",
    "        description='Select Cluster:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='300px')\n",
    "    )\n",
    "    \n",
    "    output = widgets.Output()\n",
    "    \n",
    "    def show_cluster_details(change):\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            \n",
    "            cluster_id = change['new']\n",
    "            cluster_jd_ids = cr.get_cluster_ids(cluster_id)\n",
    "            \n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"CLUSTER {cluster_id} DETAILS\")\n",
    "            print(f\"{'='*60}\")\n",
    "            print(f\"Size: {len(cluster_jd_ids)} JDs\")\n",
    "            \n",
    "            # Get cluster metadata\n",
    "            cluster_df = metadata_df[metadata_df['jd_id'].isin(cluster_jd_ids)]\n",
    "            \n",
    "            # Division distribution\n",
    "            if 'division' in cluster_df.columns:\n",
    "                print(f\"\\nüìä Division Distribution:\")\n",
    "                for div, count in cluster_df['division'].value_counts().items():\n",
    "                    print(f\"   {div}: {count} ({count/len(cluster_df):.1%})\")\n",
    "            \n",
    "            # Common titles\n",
    "            if 'title' in cluster_df.columns:\n",
    "                print(f\"\\nüìã Common Titles:\")\n",
    "                for title, count in cluster_df['title'].value_counts().head(5).items():\n",
    "                    print(f\"   {title}: {count}\")\n",
    "            \n",
    "            # Aggregate skills\n",
    "            all_skills = []\n",
    "            for jd_id in cluster_jd_ids:\n",
    "                ext = extraction_lookup.get(jd_id)\n",
    "                if ext:\n",
    "                    all_skills.extend(ext.get_all_skills_flat())\n",
    "            \n",
    "            from collections import Counter\n",
    "            skill_counts = Counter(all_skills).most_common(15)\n",
    "            \n",
    "            print(f\"\\nüõ†Ô∏è Top Skills:\")\n",
    "            for skill, count in skill_counts:\n",
    "                freq = count / len(cluster_jd_ids)\n",
    "                print(f\"   {skill}: {count} ({freq:.0%})\")\n",
    "    \n",
    "    cluster_select.observe(show_cluster_details, names='value')\n",
    "    display(cluster_select)\n",
    "    display(output)\n",
    "    \n",
    "    # Initial display\n",
    "    show_cluster_details({'new': cluster_ids[0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHASE 3 SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if clustering_results:\n",
    "    cr = clustering_results[list(clustering_results.keys())[0]]\n",
    "    \n",
    "    print(f\"\\nüìä Clustering Results:\")\n",
    "    print(f\"   Total JDs: {len(cr.ids)}\")\n",
    "    print(f\"   Clusters: {cr.n_clusters}\")\n",
    "    print(f\"   Noise: {cr.n_noise} ({cr.noise_ratio:.1%})\")\n",
    "    print(f\"   Silhouette Score: {cr.silhouette_score:.4f}\" if cr.silhouette_score else \"   Silhouette: N/A\")\n",
    "    \n",
    "    if 'division' in metadata_df.columns:\n",
    "        print(f\"   Division Purity: {overall_purity:.1%}\")\n",
    "\n",
    "print(\"\\nüí° Key Questions:\")\n",
    "print(\"   1. Is the noise ratio acceptable? (typically <20%)\")\n",
    "print(\"   2. Are cluster sizes balanced enough?\")\n",
    "print(\"   3. Do clusters align with business divisions?\")\n",
    "print(\"   4. Do the top skills per cluster make sense?\")\n",
    "\n",
    "print(\"\\n‚û°Ô∏è Next: Run Phase 4 (Aggregation) to create job archetypes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
